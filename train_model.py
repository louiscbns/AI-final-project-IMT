import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import logging
import matplotlib.pyplot as plt
import pandas as pd
from matplotlib.gridspec import GridSpec
import os
import json

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def load_data(data_dir='food-nutrients'):
    """
    Charge les embeddings et les labels depuis le fichier JSON
    """
    print("\n" + "="*50)
    print("√âTAPE 1: Chargement des donn√©es")
    print("="*50)
    
    try:
        # Charger toutes les donn√©es depuis le fichier JSON
        with open(os.path.join(data_dir, 'model_data.json'), 'r') as f:
            data = json.load(f)
            
            # Convertir les listes en arrays numpy
            X_embeddings = np.array(data['embeddings'])
            y = np.array(data['labels'])
            
            # Afficher les informations sur les donn√©es
        print(f"‚úÖ Donn√©es charg√©es avec succ√®s:")
        print(f"   - Nombre d'√©chantillons: {len(X_embeddings)}")
        print(f"   - Dimension des embeddings: {X_embeddings.shape[1]}")
        print(f"   - Nombre de caract√©ristiques: {y.shape[1]}")
        print(f"   - Caract√©ristiques: {data['metadata']['feature_names']}")
            
        return X_embeddings, y
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement des donn√©es : {e}")
        logger.error(f"Erreur lors du chargement des donn√©es : {e}")
        return None, None

def denormalize_predictions(y_normalized, data_dir='food-nutrients'):
    """
    D√©normalise les pr√©dictions en utilisant les param√®tres sauvegard√©s
    """
    mean = np.load(os.path.join(data_dir, 'scaler_mean.npy'))
    scale = np.load(os.path.join(data_dir, 'scaler_scale.npy'))
    return y_normalized * scale + mean

def plot_results(y_test, y_pred, feature_names):
    """
    Cr√©e des visualisations pour analyser les r√©sultats
    """
    print("\n" + "="*50)
    print("√âTAPE 4: Visualisation des r√©sultats")
    print("="*50)
    
    # D√©normaliser les donn√©es pour l'affichage
    y_test_denorm = denormalize_predictions(y_test)
    y_pred_denorm = denormalize_predictions(y_pred)
    
    # Cr√©er une figure avec plusieurs sous-graphiques
    plt.style.use('default')
    fig = plt.figure(figsize=(20, 20))
    gs = GridSpec(3, 3, figure=fig)
    
    # 1. Graphiques de dispersion pour chaque caract√©ristique (2x2 en haut √† gauche)
    for i, feature_name in enumerate(feature_names):
        row = i // 2
        col = i % 2
        ax = fig.add_subplot(gs[row, col])
        plt.scatter(y_test_denorm[:, i], y_pred_denorm[:, i], alpha=0.6)
        ax.plot([y_test_denorm[:, i].min(), y_test_denorm[:, i].max()], 
                [y_test_denorm[:, i].min(), y_test_denorm[:, i].max()], 
                'r--', lw=2)
        
        # Calculer le coefficient de corr√©lation
        correlation = np.corrcoef(y_test_denorm[:, i], y_pred_denorm[:, i])[0, 1]
        r2 = r2_score(y_test_denorm[:, i], y_pred_denorm[:, i])
        
        # Ajouter le coefficient de corr√©lation et R¬≤ sur le graphique
        ax.text(0.05, 0.95, 
                f'Corr√©lation: {correlation:.3f}\nR¬≤: {r2:.3f}',
                transform=ax.transAxes,
                verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        
        ax.set_xlabel(f'Valeurs r√©elles ({feature_name})')
        ax.set_ylabel(f'Pr√©dictions ({feature_name})')
        ax.set_title(f'Pr√©dictions vs Valeurs r√©elles - {feature_name} (n={len(y_test)})')
    
    # 2. Bo√Æte √† moustaches des erreurs pour les calories (en haut √† droite)
    ax = fig.add_subplot(gs[0, 2])
    errors = y_pred_denorm - y_test_denorm
    df_errors_calories = pd.DataFrame(errors[:, 0], columns=['calories'])
    df_errors_calories.boxplot(ax=ax)
    ax.set_title('Distribution des erreurs pour les calories')
    ax.set_ylabel('Erreur (Pr√©diction - R√©elle)')
    
    # 3. Bo√Æte √† moustaches des erreurs pour les autres nutriments (au milieu √† droite)
    ax = fig.add_subplot(gs[1, 2])
    df_errors_autres = pd.DataFrame(errors[:, 1:], columns=feature_names[1:])
    df_errors_autres.boxplot(ax=ax)
    ax.set_title('Distribution des erreurs pour les autres nutriments')
    ax.set_ylabel('Erreur (Pr√©diction - R√©elle)')
    plt.xticks(rotation=45)
    
    # 4. Matrice de corr√©lation des erreurs (en bas √† droite)
    ax = fig.add_subplot(gs[2, 2])
    corr_matrix = np.corrcoef(errors.T)
    im = ax.imshow(corr_matrix, cmap='coolwarm')
    ax.set_xticks(np.arange(len(feature_names)))
    ax.set_yticks(np.arange(len(feature_names)))
    ax.set_xticklabels(feature_names, rotation=45)
    ax.set_yticklabels(feature_names)
    
    # Ajouter les valeurs de corr√©lation
    for i in range(len(feature_names)):
        for j in range(len(feature_names)):
            ax.text(j, i, f'{corr_matrix[i, j]:.2f}',
                    ha='center', va='center')
    
    plt.colorbar(im, ax=ax)
    ax.set_title('Corr√©lation des erreurs entre caract√©ristiques')
    
    plt.tight_layout()
    print("‚úÖ Affichage des graphiques...")
    plt.show()
    plt.close()

def train_and_evaluate_model(X_embeddings, y):
    """
    Entra√Æne et √©value un seul mod√®le de r√©gression multiple pour pr√©dire les 4 valeurs nutritionnelles
    """
    print("\n" + "="*50)
    print("√âTAPE 2: Entra√Ænement et √©valuation du mod√®le")
    print("="*50)
    
    print("üîÑ Division des donn√©es en ensembles d'entra√Ænement et de test...")
    X_train, X_test, y_train, y_test = train_test_split(
        X_embeddings, y, test_size=0.2, random_state=42
    )
    print(f"‚úÖ Donn√©es divis√©es: {len(X_train)} √©chantillons d'entra√Ænement, {len(X_test)} √©chantillons de test")
    
    print("\nüìä Entra√Ænement du mod√®le de r√©gression multiple...")
    model = LinearRegression()
    model.fit(X_train, y_train)
    
    print("üîÑ Pr√©dictions...")
    y_pred = model.predict(X_test)
    
    # Calcul des m√©triques pour chaque caract√©ristique
    feature_names = ['calories', 'proteines', 'glucides', 'lipides']
    print("\nüìà M√©triques pour chaque caract√©ristique:")
    
    # D√©normaliser les donn√©es pour l'√©valuation
    y_test_denorm = denormalize_predictions(y_test)
    y_pred_denorm = denormalize_predictions(y_pred)
    
    for i, feature_name in enumerate(feature_names):
        mse = mean_squared_error(y_test_denorm[:, i], y_pred_denorm[:, i])
        r2 = r2_score(y_test_denorm[:, i], y_pred_denorm[:, i])
        
        print(f"\n‚úÖ {feature_name.upper()}:")
        print(f"   - Erreur quadratique moyenne (MSE): {mse:.2f}")
        print(f"   - Score R¬≤: {r2:.2f}")
        
        # Afficher les pr√©dictions vs valeurs r√©elles pour chaque √©chantillon
        print(f"\n   Comparaison pr√©dictions vs valeurs r√©elles pour {feature_name}:")
        for j in range(min(5, len(y_test))):  # Afficher seulement les 5 premiers √©chantillons
            print(f"   √âchantillon {j+1}:")
            print(f"      Valeur r√©elle: {y_test_denorm[j, i]:.2f}")
            print(f"      Pr√©diction: {y_pred_denorm[j, i]:.2f}")
    
    # Afficher les coefficients du mod√®le
    print("\nüìä Coefficients du mod√®le:")
    for i, feature_name in enumerate(feature_names):
        print(f"\nCoefficients pour {feature_name}:")
        # Afficher les 5 premiers coefficients les plus importants
        coef_indices = np.argsort(np.abs(model.coef_[i]))[-5:]
        for idx in coef_indices:
            print(f"   Embedding {idx}: {model.coef_[i][idx]:.4f}")
    
    # Cr√©er les visualisations
    plot_results(y_test, y_pred, feature_names)
    
    return model, y_pred

def main():
    print("\nüöÄ D√©marrage du processus d'entra√Ænement")
    
    # Charger les donn√©es
    X_embeddings, y = load_data()
    if X_embeddings is None or y is None:
        return
    
    # Entra√Æner et √©valuer le mod√®le
    model, y_pred = train_and_evaluate_model(X_embeddings, y)
    
    # Sauvegarder le mod√®le
    print("\n" + "="*50)
    print("√âTAPE 3: Sauvegarde du mod√®le")
    print("="*50)
    import joblib
    joblib.dump(model, 'model.joblib')
    print("‚úÖ Mod√®le sauvegard√© dans model.joblib")

if __name__ == "__main__":
    main() 