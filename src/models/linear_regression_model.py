import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns
import json
import logging
from pathlib import Path

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def load_data():
    """Charge les donn√©es depuis le fichier embeddings.json"""
    try:
        data_path = Path(__file__).parent.parent.parent / 'data' / 'food-nutrients' / 'embeddings.json'
        with open(data_path, 'r') as f:
            data = json.load(f)
        
        # Convertir les listes en arrays numpy
        X_embeddings = np.array(data['embeddings'])
        y = np.array(data['labels'])
        
        # Afficher les informations sur les donn√©es
        logging.info(f"Donn√©es charg√©es avec succ√®s:")
        logging.info(f"   - Nombre d'√©chantillons: {len(X_embeddings)}")
        logging.info(f"   - Dimension des embeddings: {X_embeddings.shape[1]}")
        logging.info(f"   - Nombre de caract√©ristiques: {y.shape[1]}")
        logging.info(f"   - Caract√©ristiques: {data['metadata']['feature_names']}")
        
        return X_embeddings, y
    except Exception as e:
        logging.error(f"Erreur lors du chargement des donn√©es : {str(e)}")
        raise

def denormalize_predictions(y_normalized, data_dir='food-nutrients'):
    """
    D√©normalise les pr√©dictions en utilisant les param√®tres sauvegard√©s lors de la normalisation
    """
    try:
        base_path = Path(__file__).parent.parent.parent / 'data' / data_dir
        mean = np.load(base_path / 'scaler_mean.npy')
        scale = np.load(base_path / 'scaler_scale.npy')
        y_denormalized = y_normalized.copy()
        y_denormalized = y_denormalized * scale + mean
        return y_denormalized
    except Exception as e:
        logging.error(f"Erreur lors de la d√©normalisation : {str(e)}")
        raise

def train_and_evaluate_model(X_embeddings, y):
    """
    Entra√Æne et √©value un mod√®le de r√©gression lin√©aire
    """
    print("\n" + "="*50)
    print("√âTAPE 2: Entra√Ænement et √©valuation du mod√®le")
    print("="*50)
    
    print("üîÑ Division des donn√©es en ensembles d'entra√Ænement et de test...")
    X_train, X_test, y_train, y_test = train_test_split(
        X_embeddings, y, test_size=0.2, random_state=42
    )
    print(f"‚úÖ Donn√©es divis√©es: {len(X_train)} √©chantillons d'entra√Ænement, {len(X_test)} √©chantillons de test")
    
    # Cr√©er et entra√Æner le mod√®le
    print("\nüìä Entra√Ænement du mod√®le de r√©gression lin√©aire...")
    model = LinearRegression()
    model.fit(X_train, y_train)
    
    # Faire des pr√©dictions
    print("üîÑ Pr√©dictions...")
    y_pred = model.predict(X_test)
    
    # D√©normaliser les donn√©es pour l'√©valuation
    y_test_denorm = denormalize_predictions(y_test)
    y_pred_denorm = denormalize_predictions(y_pred)
    
    # Cr√©er un DataFrame pour la matrice de corr√©lation
    feature_names = ['calories', 'proteines', 'glucides', 'lipides']
    df_test = pd.DataFrame(y_test_denorm, columns=feature_names)
    
    # Cr√©er la figure pour les graphiques
    plt.figure(figsize=(20, 15))
    
    # Graphiques de comparaison avec m√©triques
    for i, feature_name in enumerate(feature_names):
        plt.subplot(2, 3, i+1)
        plt.scatter(y_test_denorm[:, i], y_pred_denorm[:, i], alpha=0.5)
        
        # Ligne id√©ale (y=x)
        plt.plot([y_test_denorm[:, i].min(), y_test_denorm[:, i].max()],
                [y_test_denorm[:, i].min(), y_test_denorm[:, i].max()],
                'r--', lw=2, label='Ligne id√©ale')
        
        # Courbe de r√©gression r√©elle
        z = np.polyfit(y_test_denorm[:, i], y_pred_denorm[:, i], 1)
        p = np.poly1d(z)
        x_range = np.linspace(y_test_denorm[:, i].min(), y_test_denorm[:, i].max(), 100)
        plt.plot(x_range, p(x_range), 'b-', lw=2, label='R√©gression r√©elle')
        
        # Calculer les m√©triques
        mse = mean_squared_error(y_test_denorm[:, i], y_pred_denorm[:, i])
        mae = mean_absolute_error(y_test_denorm[:, i], y_pred_denorm[:, i])
        r2 = r2_score(y_test_denorm[:, i], y_pred_denorm[:, i])
        corr = np.corrcoef(y_test_denorm[:, i], y_pred_denorm[:, i])[0,1]
        
        # Ajouter les m√©triques au graphique
        plt.title(f'R√©gression lin√©aire - {feature_name}\n'
                 f'R¬≤ = {r2:.3f}, Corr = {corr:.3f}\n'
                 f'MSE = {mse:.2f}, MAE = {mae:.2f}')
        plt.xlabel(f'Valeurs r√©elles ({feature_name})')
        plt.ylabel(f'Pr√©dictions ({feature_name})')
        plt.legend()
    
    # Matrice de corr√©lation
    plt.subplot(2, 3, 5)
    correlation_matrix = df_test.corr()
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
    plt.title('Matrice de corr√©lation des nutriments')
    
    plt.tight_layout()
    plt.show()
    
    return model, y_pred

def main():
    print("\nüöÄ D√©marrage du processus d'entra√Ænement")
    
    # Charger les donn√©es
    X_embeddings, y = load_data()
    
    # Entra√Æner et √©valuer le mod√®le
    model, y_pred = train_and_evaluate_model(X_embeddings, y)
    
    # Sauvegarder le mod√®le
    print("\n" + "="*50)
    print("√âTAPE 3: Sauvegarde du mod√®le")
    print("="*50)
    import joblib
    model_path = Path(__file__).parent / 'linear_regression_model.joblib'
    joblib.dump(model, model_path)
    print(f"‚úÖ Mod√®le sauvegard√© dans {model_path}")

if __name__ == "__main__":
    main() 